Python microGPT Reference Output
=================================
This file contains the reference output from running the original Python microGPT
implementation on the same dataset and with the same hyperparameters.

Configuration:
- vocab size: 27
- num params: 4064
- n_embd: 16
- n_head: 4
- n_layer: 1
- block_size: 8
- training steps: 500

Training Loss Progression:
==========================
num docs: 32033
vocab size: 27
num params: 4064
step    1 /  500 | loss 3.3630
step    2 /  500 | loss 3.2917
step    3 /  500 | loss 3.2618
step    4 /  500 | loss 3.3049
step    5 /  500 | loss 3.2994
step    6 /  500 | loss 3.1489
step    7 /  500 | loss 3.1852
step    8 /  500 | loss 3.1790
step    9 /  500 | loss 3.1424
step   10 /  500 | loss 3.2763
step   11 /  500 | loss 3.0677
step   12 /  500 | loss 3.1035
step   13 /  500 | loss 3.1770
step   14 /  500 | loss 3.0856
step   15 /  500 | loss 2.9577
step   16 /  500 | loss 2.8063
step   17 /  500 | loss 2.8006
step   18 /  500 | loss 2.6902
step   19 /  500 | loss 2.9800
step   20 /  500 | loss 2.4783
step   50 /  500 | loss 2.4204
step  100 /  500 | loss 4.0093
step  150 /  500 | loss 2.6814
step  200 /  500 | loss 2.1802
step  250 /  500 | loss 2.3646
step  300 /  500 | loss 2.3226
step  350 /  500 | loss 2.1793
step  400 /  500 | loss 2.1803
step  450 /  500 | loss 2.9126
step  500 /  500 | loss 2.0859

Key Observations:
- Loss starts at ~3.36 and decreases to ~2.09
- Training shows clear learning with loss reduction
- Some variance in loss values but overall downward trend
- Final loss around 2.09 indicates reasonable learning

Inference Results (temperature=0.5):
====================================
--- inference ---
sample  1: kalia
sample  2: ameli
sample  3: aayme
sample  4: kanni
sample  5: mayein
sample  6: kanlian
sample  7: haria
sample  8: dadka
sample  9: danzea
sample 10: kanel
sample 11: donfel
sample 12: amamai
sample 13: donn
sample 14: suerme
sample 15: aman
sample 16: anuty
sample 17: aulie
sample 18: akanie
sample 19: jaylie
sample 20: karli

Quality Assessment:
- Generated names are pronounceable and look name-like
- Reasonable variety in length (4-7 characters typically)
- Names follow English phonetic patterns
- Some realistic patterns: -ia, -ie, -el, -an endings
- Overall quality: Good for a tiny model trained on 500 steps
